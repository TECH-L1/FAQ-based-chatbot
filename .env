# LLM Provider Configuration
LLM_PROVIDER=ollama

# Ollama Configuration (Default)
OLLAMA_MODEL=deepseek-r1:7b
OLLAMA_BASE_URL=http://localhost:11434

# OpenAI Configuration (Alternative)
OPENAI_API_KEY=your_actual_openai_api_key_here
OPENAI_MODEL=gpt-4

# Common LLM Settings
TEMPERATURE=0.1
MAX_TOKENS=1000

# Text Processing Configuration
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
RETRIEVAL_K=5

# Data Paths
FAQ_DATA_PATH=data/faqs
EMBEDDINGS_PATH=data/embeddings
LOGS_PATH=logs

# Logging Configuration
LOG_LEVEL=INFO